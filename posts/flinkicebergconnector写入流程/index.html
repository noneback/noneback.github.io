<!DOCTYPE html>
<html lang="en"><head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Flink-Iceberg-Connector Write Process</title>
    <meta charset="utf-8">
    <meta name="description" content="Ladder@The Iceberg community provides an official Flink Connector, and this chapter&rsquo;s source code analysis is based on that.
Overview of the Write Submission Process Flink writes data through RowData -&gt; distributeStream -&gt; WriterStream -&gt; CommitterStream. Before data is committed, it is stored as intermediate files, which become visible to the system after being committed (through writing manifest, snapshot, and metadata files).
private &lt;T&gt; DataStreamSink&lt;T&gt; chainIcebergOperators() { Preconditions.checkArgument(inputCreator != null, &#34;Please use forRowData() or forMapperOutputType() to initialize the input DataStream.">
    <meta name="author" content="NoneBack">
    <link rel="canonical" href="https://noneback.github.io/posts/flinkicebergconnector%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/">
        <meta name="google-site-verification" content="xxx">

    <link rel="alternate" type="application/rss+xml" href="https://noneback.github.io//index.xml" title="NoneBack">

    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-H0SRTJWPEK"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-H0SRTJWPEK', { 'anonymize_ip': false });
}
</script>



<script async defer data-website-id="43dc9e5a-7ab8-482e-94df-100975b5d2c8" src="https://umami-blog-pi.vercel.app/noneback-blog"></script>

    <meta property="og:title" content="Flink-Iceberg-Connector Write Process" />
<meta property="og:description" content="The Iceberg community provides an official Flink Connector, and this chapter&rsquo;s source code analysis is based on that.
Overview of the Write Submission Process Flink writes data through RowData -&gt; distributeStream -&gt; WriterStream -&gt; CommitterStream. Before data is committed, it is stored as intermediate files, which become visible to the system after being committed (through writing manifest, snapshot, and metadata files).
private &lt;T&gt; DataStreamSink&lt;T&gt; chainIcebergOperators() { Preconditions.checkArgument(inputCreator != null, &#34;Please use forRowData() or forMapperOutputType() to initialize the input DataStream." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://noneback.github.io/posts/flinkicebergconnector%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-10T10:43:38+08:00" />
<meta property="article:modified_time" content="2022-10-10T10:43:38+08:00" />


<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Flink-Iceberg-Connector Write Process"/>
<meta name="twitter:description" content="The Iceberg community provides an official Flink Connector, and this chapter&rsquo;s source code analysis is based on that.
Overview of the Write Submission Process Flink writes data through RowData -&gt; distributeStream -&gt; WriterStream -&gt; CommitterStream. Before data is committed, it is stored as intermediate files, which become visible to the system after being committed (through writing manifest, snapshot, and metadata files).
private &lt;T&gt; DataStreamSink&lt;T&gt; chainIcebergOperators() { Preconditions.checkArgument(inputCreator != null, &#34;Please use forRowData() or forMapperOutputType() to initialize the input DataStream."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://noneback.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Flink-Iceberg-Connector Write Process",
      "item": "https://noneback.github.io/posts/flinkicebergconnector%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Flink-Iceberg-Connector Write Process",
  "name": "Flink-Iceberg-Connector Write Process",
  "description": "The Iceberg community provides an official Flink Connector, and this chapter\u0026rsquo;s source code analysis is based on that.\nOverview of the Write Submission Process Flink writes data through RowData -\u0026gt; distributeStream -\u0026gt; WriterStream -\u0026gt; CommitterStream. Before data is committed, it is stored as intermediate files, which become visible to the system after being committed (through writing manifest, snapshot, and metadata files).\nprivate \u0026lt;T\u0026gt; DataStreamSink\u0026lt;T\u0026gt; chainIcebergOperators() { Preconditions.checkArgument(inputCreator != null, \u0026#34;Please use forRowData() or forMapperOutputType() to initialize the input DataStream.",
  "keywords": [
    "big data", "lake house", "stream compute", "storage"
  ],
  "articleBody": "The Iceberg community provides an official Flink Connector, and this chapter’s source code analysis is based on that.\nOverview of the Write Submission Process Flink writes data through RowData -\u003e distributeStream -\u003e WriterStream -\u003e CommitterStream. Before data is committed, it is stored as intermediate files, which become visible to the system after being committed (through writing manifest, snapshot, and metadata files).\nprivate \u003cT\u003e DataStreamSink\u003cT\u003e chainIcebergOperators() { Preconditions.checkArgument(inputCreator != null, \"Please use forRowData() or forMapperOutputType() to initialize the input DataStream.\"); Preconditions.checkNotNull(tableLoader, \"Table loader shouldn't be null\"); DataStream\u003cRowData\u003e rowDataInput = inputCreator.apply(uidPrefix); if (table == null) { tableLoader.open(); try (TableLoader loader = tableLoader) { this.table = loader.loadTable(); } catch (IOException e) { throw new UncheckedIOException(\"Failed to load iceberg table from table loader: \" + tableLoader, e); } } List\u003cInteger\u003e equalityFieldIds = checkAndGetEqualityFieldIds(); RowType flinkRowType = toFlinkRowType(table.schema(), tableSchema); DataStream\u003cRowData\u003e distributeStream = distributeDataStream( rowDataInput, table.properties(), equalityFieldIds, table.spec(), table.schema(), flinkRowType); SingleOutputStreamOperator\u003cWriteResult\u003e writerStream = appendWriter(distributeStream, flinkRowType, equalityFieldIds); SingleOutputStreamOperator\u003cVoid\u003e committerStream = appendCommitter(writerStream); return appendDummySink(committerStream); } Write Process Source Code Analysis WriteStream private SingleOutputStreamOperator\u003cWriteResult\u003e appendWriter(DataStream\u003cRowData\u003e input, RowType flinkRowType, List\u003cInteger\u003e equalityFieldIds) { boolean upsertMode = upsert || PropertyUtil.propertyAsBoolean(table.properties(), UPSERT_ENABLED, UPSERT_ENABLED_DEFAULT); if (upsertMode) { Preconditions.checkState(!overwrite, \"OVERWRITE mode shouldn't be enabled when configuring to use UPSERT data stream.\"); Preconditions.checkState(!equalityFieldIds.isEmpty(), \"Equality field columns shouldn't be empty when configuring to use UPSERT data stream.\"); if (!table.spec().isUnpartitioned()) { for (PartitionField partitionField : table.spec().fields()) { Preconditions.checkState(equalityFieldIds.contains(partitionField.sourceId()), \"In UPSERT mode, partition field '%s' should be included in equality fields: '%s'\", partitionField, equalityFieldColumns); } } } IcebergStreamWriter\u003cRowData\u003e streamWriter = createStreamWriter(table, flinkRowType, equalityFieldIds, upsertMode); int parallelism = writeParallelism == null ? input.getParallelism() : writeParallelism; SingleOutputStreamOperator\u003cWriteResult\u003e writerStream = input .transform(operatorName(ICEBERG_STREAM_WRITER_NAME), TypeInformation.of(WriteResult.class), streamWriter) .setParallelism(parallelism); if (uidPrefix != null) { writerStream = writerStream.uid(uidPrefix + \"-writer\"); } return writerStream; } The WriterStream operator is transformed from the distributeStream, with RowData as input and WriteResult as output. The transformation logic is encapsulated in the IcebergStreamWriter, which processes each element using processElement:\nprivate transient TaskWriter\u003cT\u003e writer; @Override public void processElement(StreamRecord\u003cT\u003e element) throws Exception { writer.write(element.getValue()); } IcebergStreamWriter delegates the writing to a TaskWriter created by TaskWriterFactory. The specific type could be PartitionedDeltaWriter or UnpartitionedWriter:\npublic TaskWriter\u003cRowData\u003e create() { Preconditions.checkNotNull(outputFileFactory, \"The outputFileFactory shouldn't be null if we have invoked the initialize().\"); if (equalityFieldIds == null || equalityFieldIds.isEmpty()) { if (spec.isUnpartitioned()) { return new UnpartitionedWriter\u003c\u003e(spec, format, appenderFactory, outputFileFactory, io, targetFileSizeBytes); } else { return new RowDataPartitionedFanoutWriter(spec, format, appenderFactory, outputFileFactory, io, targetFileSizeBytes, schema, flinkSchema); } } else { if (spec.isUnpartitioned()) { return new UnpartitionedDeltaWriter(spec, format, appenderFactory, outputFileFactory, io, targetFileSizeBytes, schema, flinkSchema, equalityFieldIds, upsert); } else { return new PartitionedDeltaWriter(spec, format, appenderFactory, outputFileFactory, io, targetFileSizeBytes, schema, flinkSchema, equalityFieldIds, upsert); } } } CommitterStream The CommitterStream receives WriteResult as input with no output. WriteResult contains the data files produced by WriteStream:\npublic class WriteResult implements Serializable { private DataFile[] dataFiles; private DeleteFile[] deleteFiles; private CharSequence[] referencedDataFiles; ... } The core logic for processing data file submissions is encapsulated in IcebergFilesCommitter. The IcebergFilesCommitter maintains a list of files that need to be committed for each checkpoint. Once a checkpoint completes, it tries to commit those files to Iceberg.\nclass IcebergFilesCommitter extends AbstractStreamOperator\u003cVoid\u003e implements OneInputStreamOperator\u003cWriteResult, Void\u003e, BoundedOneInput { ... private final NavigableMap\u003cLong, byte[]\u003e dataFilesPerCheckpoint = Maps.newTreeMap(); private final List\u003cWriteResult\u003e writeResultsOfCurrentCkpt = Lists.newArrayList(); private transient ListState\u003cSortedMap\u003cLong, byte[]\u003e\u003e checkpointsState; ... } The processElement method stores WriteResult from upstream in writeResultsOfCurrentCkpt:\n@Override public void processElement(StreamRecord\u003cWriteResult\u003e element) { this.writeResultsOfCurrentCkpt.add(element.getValue()); } During checkpointing (snapshotState), it saves the current checkpoint’s data in dataFilesPerCheckpoint. Later, once the checkpoint is completed (notifyCheckpointComplete), it commits the files:\npublic void snapshotState(StateSnapshotContext context) throws Exception { long checkpointId = context.getCheckpointId(); LOG.info(\"Start to flush snapshot state to state backend, table: {}, checkpointId: {}\", table, checkpointId); dataFilesPerCheckpoint.put(checkpointId, writeToManifest(checkpointId)); checkpointsState.clear(); checkpointsState.add(dataFilesPerCheckpoint); jobIdState.clear(); jobIdState.add(flinkJobId); writeResultsOfCurrentCkpt.clear(); } @Override public void notifyCheckpointComplete(long checkpointId) throws Exception { if (checkpointId \u003e maxCommittedCheckpointId) { commitUpToCheckpoint(dataFilesPerCheckpoint, flinkJobId, checkpointId); this.maxCommittedCheckpointId = checkpointId; } } The commit logic is handled by commitUpToCheckpoint, which generates a new snapshot and adds it to Iceberg’s metadata:\nprivate void commitUpToCheckpoint(NavigableMap\u003cLong, byte[]\u003e deltaManifestsMap, String newFlinkJobId, long checkpointId) throws IOException { NavigableMap\u003cLong, byte[]\u003e pendingMap = deltaManifestsMap.headMap(checkpointId, true); List\u003cManifestFile\u003e manifests = Lists.newArrayList(); NavigableMap\u003cLong, WriteResult\u003e pendingResults = Maps.newTreeMap(); for (Map.Entry\u003cLong, byte[]\u003e e : pendingMap.entrySet()) { if (Arrays.equals(EMPTY_MANIFEST_DATA, e.getValue())) { continue; } DeltaManifests deltaManifests = SimpleVersionedSerialization .readVersionAndDeSerialize(DeltaManifestsSerializer.INSTANCE, e.getValue()); pendingResults.put(e.getKey(), FlinkManifestUtil.readCompletedFiles(deltaManifests, table.io())); manifests.addAll(deltaManifests.manifests()); } int totalFiles = pendingResults.values().stream() .mapToInt(r -\u003e r.dataFiles().length + r.deleteFiles().length).sum(); continuousEmptyCheckpoints = totalFiles == 0 ? continuousEmptyCheckpoints + 1 : 0; if (totalFiles != 0 || continuousEmptyCheckpoints % maxContinuousEmptyCommits == 0) { if (replacePartitions) { replacePartitions(pendingResults, newFlinkJobId, checkpointId); } else { commitDeltaTxn(pendingResults, newFlinkJobId, checkpointId); } continuousEmptyCheckpoints = 0; } pendingMap.clear(); for (ManifestFile manifest : manifests) { try { table.io().deleteFile(manifest.path()); } catch (Exception e) { LOG.warn(\"The iceberg transaction has been committed, but we failed to clean the temporary flink manifests: {}\", manifest.path(), e); } } } public void commit(TableMetadata base, TableMetadata metadata) { if (base != current()) { if (base != null) { throw new CommitFailedException(\"Cannot commit: stale table metadata\"); } else { throw new AlreadyExistsException(\"Table already exists: %s\", tableName()); } } if (base == metadata) { LOG.info(\"Nothing to commit.\"); return; } long start = System.currentTimeMillis(); doCommit(base, metadata); deleteRemovedMetadataFiles(base, metadata); requestRefresh(); LOG.info(\"Successfully committed to table {} in {} ms\", tableName(), System.currentTimeMillis() - start); } Write Issues 1. Lots of Small Files For streaming writes, new files are generated each time, resulting in a lot of small files. While object storage supports small files well, it may increase Iceberg metadata overhead, as metadata files need to keep track of each data file. This can cause metadata files to become large and impact performance.\nSolution:\nIceberg Rewrite Action: Iceberg supports rewriting data and metadata files via Flink or Spark actions, which need to be triggered separately. Snapshot Expiry: Configure snapshot expiration to periodically delete old snapshots. import org.apache.iceberg.flink.actions.Actions; TableLoader tableLoader = TableLoader.fromHadoopTable(\"hdfs://nn:8020/warehouse/path\"); Table table = tableLoader.loadTable(); RewriteDataFilesActionResult result = Actions.forTable(table) .rewriteDataFiles() .execute(); Iceberg Flink Documentation Iceberg Maintenance Documentation\n2. Performance Issues with High Concurrency Iceberg’s writing process creates a new snapshot for each commit and uses optimistic concurrency control to handle conflicts. In high-concurrency scenarios, this can lead to many commits being retried, impacting performance.\nSolution:\nBatch Commit: Introduce a caching layer or additional service to batch commits to the data lake, reducing the number of concurrent commit operations. This cache layer can also compact multiple data files before committing. References: Optimizing Iceberg Writes for High Concurrency InfoQ Article on Iceberg Optimization\n3. Flink Iceberg Connector Limitations The Flink Iceberg Connector does not support hidden partitions or preprocessing of partition fields.\n",
  "wordCount" : "1056",
  "inLanguage": "en",
  "datePublished": "2022-10-10T10:43:38+08:00",
  "dateModified": "2022-10-10T10:43:38+08:00",
  "author":{
    "@type": "Person",
    "name": "NoneBack"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://noneback.github.io/posts/flinkicebergconnector%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "NoneBack",
    "logo": {
      "@type": "ImageObject",
      "url": "https://noneback.github.io/favicon.ico"
    }
  }
}
</script>
    <link rel="icon" href="/images/avatar.jpeg" sizes="16x16">

<link rel="apple-touch-icon" href="/images/avatar.jpeg">

<link rel="manifest" href="/images/avatar.jpeg">
    

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lxgw-wenkai-webfont@1.7.0/style.css" />

    
    
    <link rel="stylesheet" href="/css/main.min.ec28f09e946fc0df77c187fcd0d0ebde58fca6de8efb8e1620f3d45c32d4da88.css" integrity="sha256-7CjwnpRvwN93wYf80NDr3lj8pt6O&#43;44WIPPUXDLU2og=" crossorigin="anonymous" media="screen" />

    
    <link rel="stylesheet" href="/scss/highlight/github-dark.min.min.66034289ee9a113219a2c4aae0a8bd2095ab255c832a42efcf5863f10814e7a1.css" />

    
    <script src="/js/highlight.min.min.c607d6febd16934a82eb61d3a896ed9d869f54373cc63ce95864ed5488fe3128.js"></script>
    <script>hljs.highlightAll();</script>

    <script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script>
    </head>
<body>
      <main class="wrapper"><nav class="navigation">
    <section class="container">
        <a class="navigation-brand" href="/">
            HOME
        </a>
        <input type="checkbox" id="menu-toggle" />
        <label class="menu-button float-right" for="menu-toggle">
            <span></span><span></span><span></span>
        </label>
        
        <ul class="navigation-list" id="navigation-list">
            
            
            <li class="navigation-item navigation-menu">
                <a class="navigation-link" href="/posts">Blog</a>
            </li>
            
            <li class="navigation-item navigation-menu">
                <a class="navigation-link" href="/tags">Tags</a>
            </li>
            
            <li class="navigation-item navigation-menu">
                <a class="navigation-link" href="/archives">Archive</a>
            </li>
            
            <li class="navigation-item navigation-menu">
                <a class="navigation-link" href="https://umami-blog-pi.vercel.app/noneback-blog">Dashboard</a>
            </li>
            
            <li class="navigation-item navigation-menu">
                <a class="navigation-link" href="/about/">About</a>
            </li>
            
            

            <li class="navigation-item menu-separator">
                <span>|</span>
            </li>

            
            
            <li class="navigation-item navigation-social">
                <a class="navigation-link" href="https://github.com/noneback"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a>
            </li>
            
            

            <li class="navigation-item navigation-dark">
                <button id="mode" type="button" aria-label="toggle user light or dark theme">
                    <span class="toggle-dark"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path></svg></span>
                    <span class="toggle-light"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"></circle><line x1="12" y1="1" x2="12" y2="3"></line><line x1="12" y1="21" x2="12" y2="23"></line><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line><line x1="1" y1="12" x2="3" y2="12"></line><line x1="21" y1="12" x2="23" y2="12"></line><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line></svg></span>
                </button>
            </li>

            
            
            
            
            
            
            
            <li class="navigation-item navigation-language">
                <a href="https://noneback.github.io/zh/">中</a>
            </li>
            
            
            
            
        </ul>
        
    </section>
</nav>
<div id="content">
<article class="blog-single">
  <header class="blog-title">
    <h1>Flink-Iceberg-Connector Write Process</h1>
  </header>

  <p>
  <small>
    October 10, 2022&nbsp;· 1056 words&nbsp;· 5 min</small>

  <small>
      
      ·
      
      
      <a href="https://noneback.github.io/tags/big-data/">Big Data</a>
      
      <a href="https://noneback.github.io/tags/lake-house/">Lake House</a>
      
      <a href="https://noneback.github.io/tags/stream-compute/">Stream Compute</a>
      
      <a href="https://noneback.github.io/tags/storage/">Storage</a>
      
    </small>
  
<p>

  <div class="blog-toc">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#overview-of-the-write-submission-process">Overview of the Write Submission Process</a></li>
    <li><a href="#write-process-source-code-analysis">Write Process Source Code Analysis</a>
      <ul>
        <li><a href="#writestream">WriteStream</a></li>
        <li><a href="#committerstream">CommitterStream</a></li>
      </ul>
    </li>
    <li><a href="#write-issues">Write Issues</a>
      <ul>
        <li><a href="#1-lots-of-small-files">1. Lots of Small Files</a></li>
        <li><a href="#2-performance-issues-with-high-concurrency">2. Performance Issues with High Concurrency</a></li>
        <li><a href="#3-flink-iceberg-connector-limitations">3. Flink Iceberg Connector Limitations</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>

  <section class="blog-content"><p>The Iceberg community provides an official Flink Connector, and this chapter&rsquo;s source code analysis is based on that.</p>
<h2 id="overview-of-the-write-submission-process">Overview of the Write Submission Process</h2>
<p>Flink writes data through <code>RowData -&gt; distributeStream -&gt; WriterStream -&gt; CommitterStream</code>. Before data is committed, it is stored as intermediate files, which become visible to the system after being committed (through writing manifest, snapshot, and metadata files).</p>
<p><img alt="Flink-Iceberg Write Flow" src="https://intranetproxy.alipay.com/skylark/lark/0/2022/png/59256351/1655962006990-826460c7-b6fc-4efe-a8e0-65cc080ffea9.png"></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span><span style="color:#66d9ef">private</span> <span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span> DataStreamSink<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span> <span style="color:#a6e22e">chainIcebergOperators</span>() {
</span></span><span style="display:flex;"><span>    Preconditions.<span style="color:#a6e22e">checkArgument</span>(inputCreator <span style="color:#f92672">!=</span> <span style="color:#66d9ef">null</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Please use forRowData() or forMapperOutputType() to initialize the input DataStream.&#34;</span>);
</span></span><span style="display:flex;"><span>    Preconditions.<span style="color:#a6e22e">checkNotNull</span>(tableLoader, <span style="color:#e6db74">&#34;Table loader shouldn&#39;t be null&#34;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    DataStream<span style="color:#f92672">&lt;</span>RowData<span style="color:#f92672">&gt;</span> rowDataInput <span style="color:#f92672">=</span> inputCreator.<span style="color:#a6e22e">apply</span>(uidPrefix);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (table <span style="color:#f92672">==</span> <span style="color:#66d9ef">null</span>) {
</span></span><span style="display:flex;"><span>        tableLoader.<span style="color:#a6e22e">open</span>();
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">try</span> (TableLoader loader <span style="color:#f92672">=</span> tableLoader) {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">this</span>.<span style="color:#a6e22e">table</span> <span style="color:#f92672">=</span> loader.<span style="color:#a6e22e">loadTable</span>();
</span></span><span style="display:flex;"><span>        } <span style="color:#66d9ef">catch</span> (IOException e) {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">throw</span> <span style="color:#66d9ef">new</span> UncheckedIOException(<span style="color:#e6db74">&#34;Failed to load iceberg table from table loader: &#34;</span> <span style="color:#f92672">+</span> tableLoader, e);
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    List<span style="color:#f92672">&lt;</span>Integer<span style="color:#f92672">&gt;</span> equalityFieldIds <span style="color:#f92672">=</span> checkAndGetEqualityFieldIds();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    RowType flinkRowType <span style="color:#f92672">=</span> toFlinkRowType(table.<span style="color:#a6e22e">schema</span>(), tableSchema);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    DataStream<span style="color:#f92672">&lt;</span>RowData<span style="color:#f92672">&gt;</span> distributeStream <span style="color:#f92672">=</span> distributeDataStream(
</span></span><span style="display:flex;"><span>        rowDataInput, table.<span style="color:#a6e22e">properties</span>(), equalityFieldIds, table.<span style="color:#a6e22e">spec</span>(), table.<span style="color:#a6e22e">schema</span>(), flinkRowType);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    SingleOutputStreamOperator<span style="color:#f92672">&lt;</span>WriteResult<span style="color:#f92672">&gt;</span> writerStream <span style="color:#f92672">=</span> appendWriter(distributeStream, flinkRowType,
</span></span><span style="display:flex;"><span>        equalityFieldIds);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    SingleOutputStreamOperator<span style="color:#f92672">&lt;</span>Void<span style="color:#f92672">&gt;</span> committerStream <span style="color:#f92672">=</span> appendCommitter(writerStream);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> appendDummySink(committerStream);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="write-process-source-code-analysis">Write Process Source Code Analysis</h2>
<h3 id="writestream">WriteStream</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span><span style="color:#66d9ef">private</span> SingleOutputStreamOperator<span style="color:#f92672">&lt;</span>WriteResult<span style="color:#f92672">&gt;</span> <span style="color:#a6e22e">appendWriter</span>(DataStream<span style="color:#f92672">&lt;</span>RowData<span style="color:#f92672">&gt;</span> input, RowType flinkRowType,
</span></span><span style="display:flex;"><span>                                                             List<span style="color:#f92672">&lt;</span>Integer<span style="color:#f92672">&gt;</span> equalityFieldIds) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">boolean</span> upsertMode <span style="color:#f92672">=</span> upsert <span style="color:#f92672">||</span> PropertyUtil.<span style="color:#a6e22e">propertyAsBoolean</span>(table.<span style="color:#a6e22e">properties</span>(),
</span></span><span style="display:flex;"><span>        UPSERT_ENABLED, UPSERT_ENABLED_DEFAULT);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (upsertMode) {
</span></span><span style="display:flex;"><span>        Preconditions.<span style="color:#a6e22e">checkState</span>(<span style="color:#f92672">!</span>overwrite,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;OVERWRITE mode shouldn&#39;t be enabled when configuring to use UPSERT data stream.&#34;</span>);
</span></span><span style="display:flex;"><span>        Preconditions.<span style="color:#a6e22e">checkState</span>(<span style="color:#f92672">!</span>equalityFieldIds.<span style="color:#a6e22e">isEmpty</span>(),
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;Equality field columns shouldn&#39;t be empty when configuring to use UPSERT data stream.&#34;</span>);
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> (<span style="color:#f92672">!</span>table.<span style="color:#a6e22e">spec</span>().<span style="color:#a6e22e">isUnpartitioned</span>()) {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> (PartitionField partitionField : table.<span style="color:#a6e22e">spec</span>().<span style="color:#a6e22e">fields</span>()) {
</span></span><span style="display:flex;"><span>                Preconditions.<span style="color:#a6e22e">checkState</span>(equalityFieldIds.<span style="color:#a6e22e">contains</span>(partitionField.<span style="color:#a6e22e">sourceId</span>()),
</span></span><span style="display:flex;"><span>                    <span style="color:#e6db74">&#34;In UPSERT mode, partition field &#39;%s&#39; should be included in equality fields: &#39;%s&#39;&#34;</span>,
</span></span><span style="display:flex;"><span>                    partitionField, equalityFieldColumns);
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    IcebergStreamWriter<span style="color:#f92672">&lt;</span>RowData<span style="color:#f92672">&gt;</span> streamWriter <span style="color:#f92672">=</span> createStreamWriter(table, flinkRowType, equalityFieldIds, upsertMode);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> parallelism <span style="color:#f92672">=</span> writeParallelism <span style="color:#f92672">==</span> <span style="color:#66d9ef">null</span> <span style="color:#f92672">?</span> input.<span style="color:#a6e22e">getParallelism</span>() : writeParallelism;
</span></span><span style="display:flex;"><span>    SingleOutputStreamOperator<span style="color:#f92672">&lt;</span>WriteResult<span style="color:#f92672">&gt;</span> writerStream <span style="color:#f92672">=</span> input
</span></span><span style="display:flex;"><span>        .<span style="color:#a6e22e">transform</span>(operatorName(ICEBERG_STREAM_WRITER_NAME), TypeInformation.<span style="color:#a6e22e">of</span>(WriteResult.<span style="color:#a6e22e">class</span>), streamWriter)
</span></span><span style="display:flex;"><span>        .<span style="color:#a6e22e">setParallelism</span>(parallelism);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (uidPrefix <span style="color:#f92672">!=</span> <span style="color:#66d9ef">null</span>) {
</span></span><span style="display:flex;"><span>        writerStream <span style="color:#f92672">=</span> writerStream.<span style="color:#a6e22e">uid</span>(uidPrefix <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;-writer&#34;</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> writerStream;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <code>WriterStream</code> operator is transformed from the <code>distributeStream</code>, with <code>RowData</code> as input and <code>WriteResult</code> as output. The transformation logic is encapsulated in the <code>IcebergStreamWriter</code>, which processes each element using <code>processElement</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span><span style="color:#66d9ef">private</span> <span style="color:#66d9ef">transient</span> TaskWriter<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span> writer;
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@Override</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">processElement</span>(StreamRecord<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span> element) <span style="color:#66d9ef">throws</span> Exception {
</span></span><span style="display:flex;"><span>    writer.<span style="color:#a6e22e">write</span>(element.<span style="color:#a6e22e">getValue</span>());
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p><code>IcebergStreamWriter</code> delegates the writing to a <code>TaskWriter</code> created by <code>TaskWriterFactory</code>. The specific type could be <code>PartitionedDeltaWriter</code> or <code>UnpartitionedWriter</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span><span style="color:#66d9ef">public</span> TaskWriter<span style="color:#f92672">&lt;</span>RowData<span style="color:#f92672">&gt;</span> <span style="color:#a6e22e">create</span>() {
</span></span><span style="display:flex;"><span>    Preconditions.<span style="color:#a6e22e">checkNotNull</span>(outputFileFactory,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;The outputFileFactory shouldn&#39;t be null if we have invoked the initialize().&#34;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (equalityFieldIds <span style="color:#f92672">==</span> <span style="color:#66d9ef">null</span> <span style="color:#f92672">||</span> equalityFieldIds.<span style="color:#a6e22e">isEmpty</span>()) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> (spec.<span style="color:#a6e22e">isUnpartitioned</span>()) {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">new</span> UnpartitionedWriter<span style="color:#f92672">&lt;&gt;</span>(spec, format, appenderFactory, outputFileFactory, io, targetFileSizeBytes);
</span></span><span style="display:flex;"><span>        } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">new</span> RowDataPartitionedFanoutWriter(spec, format, appenderFactory, outputFileFactory,
</span></span><span style="display:flex;"><span>                io, targetFileSizeBytes, schema, flinkSchema);
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> (spec.<span style="color:#a6e22e">isUnpartitioned</span>()) {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">new</span> UnpartitionedDeltaWriter(spec, format, appenderFactory, outputFileFactory, io,
</span></span><span style="display:flex;"><span>                targetFileSizeBytes, schema, flinkSchema, equalityFieldIds, upsert);
</span></span><span style="display:flex;"><span>        } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">new</span> PartitionedDeltaWriter(spec, format, appenderFactory, outputFileFactory, io,
</span></span><span style="display:flex;"><span>                targetFileSizeBytes, schema, flinkSchema, equalityFieldIds, upsert);
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h3 id="committerstream">CommitterStream</h3>
<p>The <code>CommitterStream</code> receives <code>WriteResult</code> as input with no output. <code>WriteResult</code> contains the data files produced by <code>WriteStream</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span><span style="color:#66d9ef">public</span> <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">WriteResult</span> <span style="color:#66d9ef">implements</span> Serializable {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">private</span> DataFile<span style="color:#f92672">[]</span> dataFiles;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">private</span> DeleteFile<span style="color:#f92672">[]</span> deleteFiles;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">private</span> CharSequence<span style="color:#f92672">[]</span> referencedDataFiles;
</span></span><span style="display:flex;"><span>  ...
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The core logic for processing data file submissions is encapsulated in <code>IcebergFilesCommitter</code>. The <code>IcebergFilesCommitter</code> maintains a list of files that need to be committed for each checkpoint. Once a checkpoint completes, it tries to commit those files to Iceberg.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">IcebergFilesCommitter</span> <span style="color:#66d9ef">extends</span> AbstractStreamOperator<span style="color:#f92672">&lt;</span>Void<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">implements</span> OneInputStreamOperator<span style="color:#f92672">&lt;</span>WriteResult, Void<span style="color:#f92672">&gt;</span>, BoundedOneInput {
</span></span><span style="display:flex;"><span>    ...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">private</span> <span style="color:#66d9ef">final</span> NavigableMap<span style="color:#f92672">&lt;</span>Long, <span style="color:#66d9ef">byte</span><span style="color:#f92672">[]&gt;</span> dataFilesPerCheckpoint <span style="color:#f92672">=</span> Maps.<span style="color:#a6e22e">newTreeMap</span>();
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">private</span> <span style="color:#66d9ef">final</span> List<span style="color:#f92672">&lt;</span>WriteResult<span style="color:#f92672">&gt;</span> writeResultsOfCurrentCkpt <span style="color:#f92672">=</span> Lists.<span style="color:#a6e22e">newArrayList</span>();
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">private</span> <span style="color:#66d9ef">transient</span> ListState<span style="color:#f92672">&lt;</span>SortedMap<span style="color:#f92672">&lt;</span>Long, <span style="color:#66d9ef">byte</span><span style="color:#f92672">[]&gt;&gt;</span> checkpointsState;
</span></span><span style="display:flex;"><span>    ...
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <code>processElement</code> method stores <code>WriteResult</code> from upstream in <code>writeResultsOfCurrentCkpt</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span><span style="color:#a6e22e">@Override</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">processElement</span>(StreamRecord<span style="color:#f92672">&lt;</span>WriteResult<span style="color:#f92672">&gt;</span> element) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">this</span>.<span style="color:#a6e22e">writeResultsOfCurrentCkpt</span>.<span style="color:#a6e22e">add</span>(element.<span style="color:#a6e22e">getValue</span>());
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>During checkpointing (<code>snapshotState</code>), it saves the current checkpoint&rsquo;s data in <code>dataFilesPerCheckpoint</code>. Later, once the checkpoint is completed (<code>notifyCheckpointComplete</code>), it commits the files:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span><span style="color:#66d9ef">public</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">snapshotState</span>(StateSnapshotContext context) <span style="color:#66d9ef">throws</span> Exception {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">long</span> checkpointId <span style="color:#f92672">=</span> context.<span style="color:#a6e22e">getCheckpointId</span>();
</span></span><span style="display:flex;"><span>    LOG.<span style="color:#a6e22e">info</span>(<span style="color:#e6db74">&#34;Start to flush snapshot state to state backend, table: {}, checkpointId: {}&#34;</span>, table, checkpointId);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    dataFilesPerCheckpoint.<span style="color:#a6e22e">put</span>(checkpointId, writeToManifest(checkpointId));
</span></span><span style="display:flex;"><span>    checkpointsState.<span style="color:#a6e22e">clear</span>();
</span></span><span style="display:flex;"><span>    checkpointsState.<span style="color:#a6e22e">add</span>(dataFilesPerCheckpoint);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    jobIdState.<span style="color:#a6e22e">clear</span>();
</span></span><span style="display:flex;"><span>    jobIdState.<span style="color:#a6e22e">add</span>(flinkJobId);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    writeResultsOfCurrentCkpt.<span style="color:#a6e22e">clear</span>();
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@Override</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">notifyCheckpointComplete</span>(<span style="color:#66d9ef">long</span> checkpointId) <span style="color:#66d9ef">throws</span> Exception {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (checkpointId <span style="color:#f92672">&gt;</span> maxCommittedCheckpointId) {
</span></span><span style="display:flex;"><span>        commitUpToCheckpoint(dataFilesPerCheckpoint, flinkJobId, checkpointId);
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">this</span>.<span style="color:#a6e22e">maxCommittedCheckpointId</span> <span style="color:#f92672">=</span> checkpointId;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The commit logic is handled by <code>commitUpToCheckpoint</code>, which generates a new snapshot and adds it to Iceberg&rsquo;s metadata:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span><span style="color:#66d9ef">private</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">commitUpToCheckpoint</span>(NavigableMap<span style="color:#f92672">&lt;</span>Long, <span style="color:#66d9ef">byte</span><span style="color:#f92672">[]&gt;</span> deltaManifestsMap,
</span></span><span style="display:flex;"><span>                                  String newFlinkJobId,
</span></span><span style="display:flex;"><span>                                  <span style="color:#66d9ef">long</span> checkpointId) <span style="color:#66d9ef">throws</span> IOException {
</span></span><span style="display:flex;"><span>    NavigableMap<span style="color:#f92672">&lt;</span>Long, <span style="color:#66d9ef">byte</span><span style="color:#f92672">[]&gt;</span> pendingMap <span style="color:#f92672">=</span> deltaManifestsMap.<span style="color:#a6e22e">headMap</span>(checkpointId, <span style="color:#66d9ef">true</span>);
</span></span><span style="display:flex;"><span>    List<span style="color:#f92672">&lt;</span>ManifestFile<span style="color:#f92672">&gt;</span> manifests <span style="color:#f92672">=</span> Lists.<span style="color:#a6e22e">newArrayList</span>();
</span></span><span style="display:flex;"><span>    NavigableMap<span style="color:#f92672">&lt;</span>Long, WriteResult<span style="color:#f92672">&gt;</span> pendingResults <span style="color:#f92672">=</span> Maps.<span style="color:#a6e22e">newTreeMap</span>();
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> (Map.<span style="color:#a6e22e">Entry</span><span style="color:#f92672">&lt;</span>Long, <span style="color:#66d9ef">byte</span><span style="color:#f92672">[]&gt;</span> e : pendingMap.<span style="color:#a6e22e">entrySet</span>()) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> (Arrays.<span style="color:#a6e22e">equals</span>(EMPTY_MANIFEST_DATA, e.<span style="color:#a6e22e">getValue</span>())) {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">continue</span>;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        DeltaManifests deltaManifests <span style="color:#f92672">=</span> SimpleVersionedSerialization
</span></span><span style="display:flex;"><span>            .<span style="color:#a6e22e">readVersionAndDeSerialize</span>(DeltaManifestsSerializer.<span style="color:#a6e22e">INSTANCE</span>, e.<span style="color:#a6e22e">getValue</span>());
</span></span><span style="display:flex;"><span>        pendingResults.<span style="color:#a6e22e">put</span>(e.<span style="color:#a6e22e">getKey</span>(), FlinkManifestUtil.<span style="color:#a6e22e">readCompletedFiles</span>(deltaManifests, table.<span style="color:#a6e22e">io</span>()));
</span></span><span style="display:flex;"><span>        manifests.<span style="color:#a6e22e">addAll</span>(deltaManifests.<span style="color:#a6e22e">manifests</span>());
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> totalFiles <span style="color:#f92672">=</span> pendingResults.<span style="color:#a6e22e">values</span>().<span style="color:#a6e22e">stream</span>()
</span></span><span style="display:flex;"><span>        .<span style="color:#a6e22e">mapToInt</span>(r <span style="color:#f92672">-&gt;</span> r.<span style="color:#a6e22e">dataFiles</span>().<span style="color:#a6e22e">length</span> <span style="color:#f92672">+</span> r.<span style="color:#a6e22e">deleteFiles</span>().<span style="color:#a6e22e">length</span>).<span style="color:#a6e22e">sum</span>();
</span></span><span style="display:flex;"><span>    continuousEmptyCheckpoints <span style="color:#f92672">=</span> totalFiles <span style="color:#f92672">==</span> 0 <span style="color:#f92672">?</span> continuousEmptyCheckpoints <span style="color:#f92672">+</span> 1 : 0;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (totalFiles <span style="color:#f92672">!=</span> 0 <span style="color:#f92672">||</span> continuousEmptyCheckpoints <span style="color:#f92672">%</span> maxContinuousEmptyCommits <span style="color:#f92672">==</span> 0) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> (replacePartitions) {
</span></span><span style="display:flex;"><span>            replacePartitions(pendingResults, newFlinkJobId, checkpointId);
</span></span><span style="display:flex;"><span>        } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>            commitDeltaTxn(pendingResults, newFlinkJobId, checkpointId);
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        continuousEmptyCheckpoints <span style="color:#f92672">=</span> 0;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    pendingMap.<span style="color:#a6e22e">clear</span>();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> (ManifestFile manifest : manifests) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">try</span> {
</span></span><span style="display:flex;"><span>            table.<span style="color:#a6e22e">io</span>().<span style="color:#a6e22e">deleteFile</span>(manifest.<span style="color:#a6e22e">path</span>());
</span></span><span style="display:flex;"><span>        } <span style="color:#66d9ef">catch</span> (Exception e) {
</span></span><span style="display:flex;"><span>            LOG.<span style="color:#a6e22e">warn</span>(<span style="color:#e6db74">&#34;The iceberg transaction has been committed, but we failed to clean the temporary flink manifests: {}&#34;</span>,
</span></span><span style="display:flex;"><span>                manifest.<span style="color:#a6e22e">path</span>(), e);
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span><span style="color:#66d9ef">public</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">commit</span>(TableMetadata base, TableMetadata metadata) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (base <span style="color:#f92672">!=</span> current()) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> (base <span style="color:#f92672">!=</span> <span style="color:#66d9ef">null</span>) {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">throw</span> <span style="color:#66d9ef">new</span> CommitFailedException(<span style="color:#e6db74">&#34;Cannot commit: stale table metadata&#34;</span>);
</span></span><span style="display:flex;"><span>        } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">throw</span> <span style="color:#66d9ef">new</span> AlreadyExistsException(<span style="color:#e6db74">&#34;Table already exists: %s&#34;</span>, tableName());
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (base <span style="color:#f92672">==</span> metadata) {
</span></span><span style="display:flex;"><span>        LOG.<span style="color:#a6e22e">info</span>(<span style="color:#e6db74">&#34;Nothing to commit.&#34;</span>);
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">long</span> start <span style="color:#f92672">=</span> System.<span style="color:#a6e22e">currentTimeMillis</span>();
</span></span><span style="display:flex;"><span>    doCommit(base, metadata);
</span></span><span style="display:flex;"><span>    deleteRemovedMetadataFiles(base, metadata);
</span></span><span style="display:flex;"><span>    requestRefresh();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    LOG.<span style="color:#a6e22e">info</span>(<span style="color:#e6db74">&#34;Successfully committed to table {} in {} ms&#34;</span>,
</span></span><span style="display:flex;"><span>        tableName(),
</span></span><span style="display:flex;"><span>        System.<span style="color:#a6e22e">currentTimeMillis</span>() <span style="color:#f92672">-</span> start);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="write-issues">Write Issues</h2>
<h3 id="1-lots-of-small-files">1. Lots of Small Files</h3>
<p>For streaming writes, new files are generated each time, resulting in a lot of small files. While object storage supports small files well, it may increase Iceberg metadata overhead, as metadata files need to keep track of each data file. This can cause metadata files to become large and impact performance.</p>
<p><strong>Solution:</strong></p>
<ul>
<li><strong>Iceberg Rewrite Action</strong>: Iceberg supports rewriting data and metadata files via Flink or Spark actions, which need to be triggered separately.</li>
<li><strong>Snapshot Expiry</strong>: Configure snapshot expiration to periodically delete old snapshots.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-java" data-lang="java"><span style="display:flex;"><span><span style="color:#f92672">import</span> org.apache.iceberg.flink.actions.Actions;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>TableLoader tableLoader <span style="color:#f92672">=</span> TableLoader.<span style="color:#a6e22e">fromHadoopTable</span>(<span style="color:#e6db74">&#34;hdfs://nn:8020/warehouse/path&#34;</span>);
</span></span><span style="display:flex;"><span>Table table <span style="color:#f92672">=</span> tableLoader.<span style="color:#a6e22e">loadTable</span>();
</span></span><span style="display:flex;"><span>RewriteDataFilesActionResult result <span style="color:#f92672">=</span> Actions.<span style="color:#a6e22e">forTable</span>(table)
</span></span><span style="display:flex;"><span>    .<span style="color:#a6e22e">rewriteDataFiles</span>()
</span></span><span style="display:flex;"><span>    .<span style="color:#a6e22e">execute</span>();
</span></span></code></pre></div><p><a href="https://iceberg.apache.org/docs/latest/flink/">Iceberg Flink Documentation</a>
<a href="https://iceberg.apache.org/docs/latest/maintenance/">Iceberg Maintenance Documentation</a></p>
<h3 id="2-performance-issues-with-high-concurrency">2. Performance Issues with High Concurrency</h3>
<p>Iceberg&rsquo;s writing process creates a new snapshot for each commit and uses optimistic concurrency control to handle conflicts. In high-concurrency scenarios, this can lead to many commits being retried, impacting performance.</p>
<p><strong>Solution:</strong></p>
<ul>
<li><strong>Batch Commit</strong>: Introduce a caching layer or additional service to batch commits to the data lake, reducing the number of concurrent commit operations. This cache layer can also compact multiple data files before committing.</li>
</ul>
<blockquote>
<p>References:
<a href="https://zhuanlan.zhihu.com/p/472617094">Optimizing Iceberg Writes for High Concurrency</a>
<a href="https://www.infoq.cn/article/hfft7c7ahoomgayjsouz">InfoQ Article on Iceberg Optimization</a></p>
</blockquote>
<h3 id="3-flink-iceberg-connector-limitations">3. Flink Iceberg Connector Limitations</h3>
<p>The Flink Iceberg Connector does not support hidden partitions or preprocessing of partition fields.</p>
</section>

  
  
  <div class="paginator">
    
    <a class="prev" href="https://noneback.github.io/posts/mit6.824-zookeeper/">
      <svg class="icon" width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M3.77086 21.1546C11.0491 22.698 21.4339 21.7773 21.4339 16.3608V4.63375C21.4339 3.93962 21.3581 3.30535 21.1917 2.76787M3.77086 21.1546C1.9934 20.7777 0.973585 18.7264 1.08749 16.688C1.2668 13.479 1.15721 9.43135 1.00513 6.21507C0.87809 3.52811 3.12891 1.16316 5.51029 1.25008C9.76594 1.40542 15.377 1.20229 18.7912 1.00542C20.0864 0.930734 20.8406 1.63385 21.1917 2.76787M3.77086 21.1546C4.56586 21.4723 5.49168 21.7879 6.5 22.0658M21.1917 2.76787C23.1097 4.18217 23.13 12.4191 22.9004 16.3608C20.8478 24.0194 12.3061 23.6662 6.5 22.0658M21.1917 2.76787C21.7612 4.51192 22.7203 9.67216 22 16.3608C21.2797 23.0494 11.3665 22.9511 6.5 22.0658M9.94496 9C9.28897 9.61644 7.63215 10.997 6.04814 11.7966C5.98257 11.8297 5.98456 11.9753 6.05061 12.0063C7.05496 12.4779 8.92941 13.9264 9.94496 15M6.44444 11.9667C8.86549 12.0608 14 12 16 11" stroke="currentColor" stroke-linecap="round"/>
      </svg>
      <span>MIT6.824-ZooKeeper</span></a>
    
    
    <a class="next" href="https://noneback.github.io/posts/apacheorc%E8%B0%83%E7%A0%94/"><span>Apache-ORC Quick Research</span>
      <svg class="icon" width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M3.77086 21.1546C11.0491 22.698 21.4339 21.7773 21.4339 16.3608V4.63375C21.4339 3.93962 21.3581 3.30535 21.1917 2.76787M3.77086 21.1546C1.9934 20.7777 0.973585 18.7264 1.08749 16.688C1.2668 13.479 1.15721 9.43135 1.00513 6.21507C0.87809 3.52811 3.12891 1.16316 5.51029 1.25008C9.76594 1.40542 15.377 1.20229 18.7912 1.00542C20.0864 0.930734 20.8406 1.63385 21.1917 2.76787M3.77086 21.1546C4.56586 21.4723 5.49168 21.7879 6.5 22.0658M21.1917 2.76787C23.1097 4.18217 23.13 12.4191 22.9004 16.3608C20.8478 24.0194 12.3061 23.6662 6.5 22.0658M21.1917 2.76787C21.7612 4.51192 22.7203 9.67216 22 16.3608C21.2797 23.0494 11.3665 22.9511 6.5 22.0658M12.055 9C12.711 9.61644 14.3679 10.997 15.9519 11.7966C16.0174 11.8297 16.0154 11.9753 15.9494 12.0063C14.945 12.4779 13.0706 13.9264 12.055 15M15.5556 11.9667C13.1345 12.0608 8 12 6 11" stroke="currentColor" stroke-linecap="round"/>
      </svg>
    </a>
    
  </div>
  

  


</article>

        </div><footer class="footer">
  <p>&copy; 2024 <a href="https://noneback.github.io/">NoneBack</a>
    Powered by
    <a href="https://gohugo.io/" rel="noopener" target="_blank">Hugo️️</a>
    <a href="https://github.com/guangzhengli/hugo-theme-ladder" rel="noopener" target="_blank">Ladder</a>
️  </p>
</footer>

<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M10.5376 22.7916C11.0152 22.7207 22.5795 21.1781 22.0978 10.4211C22.0536 9.43274 21.9303 8.53367 21.7387 7.71865M10.5376 22.7916C16.876 22.3728 20.0969 19.8899 21.5383 16.9142M10.5376 22.7916C9.7707 22.9055 8.97982 22.8964 8.19743 22.7725M21.7387 7.71865C21.4988 6.69828 21.1518 5.80967 20.7188 5.04257M21.7387 7.71865C22.6022 10.1105 23.0542 13.7848 21.5383 16.9142M20.7188 5.04257C17.1684 -1.24629 7.83127 0.632493 4.27577 5.04257C2.88063 6.77451 -0.0433281 11.1668 1.38159 16.6571C2.27481 20.0988 5.17269 22.2936 8.19743 22.7725M20.7188 5.04257C22.0697 6.9404 24.0299 11.3848 22.3541 15.4153M21.5383 16.9142C21.8737 16.4251 22.1428 15.9235 22.3541 15.4153M8.19743 22.7725C12.1971 23.4683 20.6281 22.971 22.3541 15.4153M14 10.945C13.3836 10.289 12.003 8.63215 11.2034 7.04814C11.1703 6.98257 11.0247 6.98456 10.9937 7.05061C10.5221 8.05496 9.07362 9.92941 8 10.945M11.0333 7.44444C10.9392 9.86549 11 15 12 17" stroke="currentColor" stroke-linecap="round"/>
    </svg>
</a>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>

<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'Copy';

        function copyingDone() {
            copybutton.innerHTML = 'Copied';
            setTimeout(() => {
                copybutton.innerHTML = 'Copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });
        codeblock.parentNode.appendChild(copybutton);
    });
</script></main>
    </body><script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js" integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

  <script>
      const images = Array.from(document.querySelectorAll(".blog-content img"));
      images.forEach(img => {
          mediumZoom(img, {
              margin: 10,  
              scrollOffset: 40,  
              container: null,  
              template: null,  
              background: 'rgba(0, 0, 0, 0.5)'
          });
      });
  </script>

  
  <script src="/main.min.6bb26b69159420159c74dc9e097b06a578ed2b68c701466a91a44a9632d851bd0af167a1b30012387b4c512b48ad9ad4d3394e04d77ae38d57e1920fe4ed34fe.js" integrity="sha512-a7JraRWUIBWcdNyeCXsGpXjtK2jHAUZqkaRKljLYUb0K8WehswASOHtMUStIrZrU0zlOBNd6441X4ZIP5O00/g==" crossorigin="anonymous" defer></script></html>
